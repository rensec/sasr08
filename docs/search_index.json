[["index.html", "SaSR 8: Social Network Analysis About Usage Credits and further resources", " SaSR 8: Social Network Analysis Rense Corten &amp; Deni Mazrekaj 2025-05-15 About This page contains tutorials for the Utrecht University course SaSR 8/Research practicum 2: Social network analysis (200400071). Usage To use these tutorials, we suggest that you: Open a new R script; Copy-paste the code from the tutorials into your R script as you read along; Run the code from your script while reading along, to verify that your results are the same; Afterwards, save your R script under an informative name so that you can refer to it and reuse it later. A big part of effective data analysis is realizing that you’ve solved particular problems before and being able to find and recycle your earlier code! Credits and further resources There are many excellent tutorials for social network analysis in R, and the tutorials on this page are inspired by and builds on some of them. Particularly useful were: The tutorials that accompany the book Network Analysis: Integrating Social Network Theory, Method, and Application with R by Craig Rawlings, Jeffrey A. Smith, James Moody, and Daniel McFarland (2023); The tutorials that accompany the book Analyzing Social Networks Using R by Stephen Borgatti, Martin Everett, Jeffrey Johnson and Filip Agneessens; The tutorials available on the Statnet website, created by the Statnet team. "],["tut_data_handling.html", "1 Handling social network data in R 1.1 Getting network data into R: the igraph package 1.2 The reverse direction: exporting from igraph objects 1.3 Getting network data into R: the network package 1.4 Modifying networks in igraph", " 1 Handling social network data in R This tutorial demonstrates some data handling procedures for relational (social network) data. In particular, we’ll learn: How to read network data from a file and convert them into a ‘network object’ that R can work with, using the common network-oriented packages igraph and network; How to move back and forth between different types of data formats for relational data; How to perform basic data manipulation procedures in igraph;1 How to produce a basic visualization of a network. We start by loading some useful packages: igraph and network are packages specifically for handling network data; reshape2 and tidyverse are more general-purpose packages that contain useful procedures. NOTE: if you get any “there is no package called…” error messages, make sure you install these packages first using the install.packages() function (not included here). library(network) library(igraph) library(reshape2) library(tidyverse) 1.1 Getting network data into R: the igraph package Network analysis packages such as igraph handle data efficiently by storing data in their own type of objects, which basically ensure that all procedures make sense for network data. Moreover, a network object as used by igraph allows to include the information on both edges and nodes of a network in a single “box” (and potentially other information about the network too). The raw data that we use to create these network objects may come in different ‘shapes’, such as adjacency matrices, edge lists, or adjacency lists. In the following, we discuss how to turn data objects of these different shapes into igraph network objects. 1.1.1 From adjacency matrix to igraph object We start by reading some network data from a file (from the internet, in this case). A simple and very common way to store data is as “comma-separated values” (CSV). Let’s load some “toy data”: url1 &lt;- &quot;https://github.com/rensec/sasr08/raw/main/g_adj_matrix_simple.csv&quot; g_matrix &lt;- read.csv(file = url1, header = FALSE) g_matrix ## V1 V2 V3 V4 V5 ## 1 0 1 0 1 0 ## 2 0 0 1 0 0 ## 3 1 0 0 0 0 ## 4 0 0 0 0 0 ## 5 0 0 0 0 0 These data are stored in the shape of an adjacency matrix, meaning that it is a square matrix in which both the rows and the columns represent nodes, and the values in the cells indicate the status of the edges between these nodes. While reading the data, R automatically created column names and loaded the data as a data frame: class(g_matrix) ## [1] &quot;data.frame&quot; For network analysis, this is often not practical; for example we may want to do matrix calculations. So instead, let’s turn this into a matrix object: g_matrix &lt;- as.matrix(g_matrix) g_matrix ## V1 V2 V3 V4 V5 ## [1,] 0 1 0 1 0 ## [2,] 0 0 1 0 0 ## [3,] 1 0 0 0 0 ## [4,] 0 0 0 0 0 ## [5,] 0 0 0 0 0 Now, conceptually, the data still have the shape of an adjacency matrix, but in R, it is now stored as an object of class ‘matrix’. For clarity, we also add row- and column names, simply numbering them: rownames(g_matrix) &lt;- 1:nrow(g_matrix) colnames(g_matrix) &lt;- 1:ncol(g_matrix) g_matrix ## 1 2 3 4 5 ## 1 0 1 0 1 0 ## 2 0 0 1 0 0 ## 3 1 0 0 0 0 ## 4 0 0 0 0 0 ## 5 0 0 0 0 0 QUESTION: How many nodes are included in this matrix, and how many edges are there between these nodes? Typically, information about nodes and edges are stored in separate files. In our next step, we’re reading an attribute of the nodes: g_nodes_age &lt;- read.csv(file = &quot;https://github.com/rensec/sasr08/raw/main/g_nodes_age.csv&quot;) g_nodes_age ## id age ## 1 1 20 ## 2 2 21 ## 3 3 25 ## 4 4 NA ## 5 5 21 We now have information about nodes and edges loaded into R. However, to R, these are just like any data; it doesn’t “know” that these are network data. In order to be able to use specific SNA procedures, we first need to create network objects, which is what we’ll do next. NOTE: the data that we’ve loaded now just happened to have the shape of an adjacency matrix; it is also possible to store network data to a file in other shapes. We’ll get to that later. To create an igraph network object from our matrix object we run: g &lt;- graph_from_adjacency_matrix(g_matrix) class(g) ## [1] &quot;igraph&quot; g ## IGRAPH 1c7e4a3 DN-- 5 4 -- ## + attr: name (v/c) ## + edges from 1c7e4a3 (vertex names): ## [1] 1-&gt;2 1-&gt;4 2-&gt;3 3-&gt;1 The output from running “g” already shows that this is now a network object (specifically: an object of the class “igraph”, as shown by class()): R interprets the object as a network and shows us the edges in the network. This also means that other R functions - to the extent that they have network methods implemented - now automatically recognize g as a network object and will behave accordingly (note that this is a key feature of R as an “object-oriented language”). For example, we can now run the standard plot() function and it will create a network map: plot(g) Now we can also add node attributes to the object (in this case we have only one): g &lt;- set_vertex_attr(g, name = &quot;age&quot;, value = g_nodes_age$age) 1.1.2 From edge list to igraph object A very common shape that network data come in is the edge list. This is a data matrix with usually just two columns, in which every row represents an edge between two nodes, listed in the columns. The file ‘g_elist.csv’ contains an edge list for the same network ‘g’ that we saw above. Let’s load the file into a data frame: g_elist &lt;- read.csv(file = &quot;https://github.com/rensec/sasr08/raw/main/g_elist.csv&quot;) g_elist ## from to ## 1 1 2 ## 2 2 3 ## 3 3 1 ## 4 1 4 Here, each row represents an edge between the nodes listed in the columns ‘from’ and ‘to’. We can create an igraph network object from the edge list as follows: g_from_elist &lt;- graph_from_data_frame(g_elist) plot(g_from_elist) If you compare this network with the one pictured earlier, you’ll notice an important difference: we lost the isolate! This is an important limitation of edge lists: due to their nature, they do not include isolates. To include the isolate in the network object, we need to feed the function also the list of all the nodes. Fortunately we already have the complete list of nodes, include in our data object with node attributes (g_nodes_age). We can include the list of nodes when we import the edge list into the igraph object: g_from_elist &lt;- graph_from_data_frame(g_elist, vertices = g_nodes_age) plot(g_from_elist) Now the isolate is included as it should. Thus, when importing edge lists, it is important to always include a complete node list as well (unless you are certain that the edge list includes all nodes)! Note also that now we have included the node attribute ‘age’ already with the node list when we created the network object. Thus, we so far have seen two ways to add node attributes to a network object: Include them directly with a node list when you first create the network object, as specified in the ‘vertices’ argument of a function like graph_from_data_frame(); Add them afterwards using set_vertex_attr(). Assignment: from the code snippets above, construct a complete “pipeline” to go from the edge list to the igraph object. Start from g_elist. Plot the resulting network. Store the code somewhere for later use. 1.1.3 From adjacency list to igraph object Another common shape for network data, especially if collected via survey methods, is the adjacency list. In this shape, we have a row for each node, and columns that indicate the first, second, third… etc. connection of each node. The file g_adj_list.csv is an example of this format (it is again our toy network as used in the previous excercises). g_adj_list &lt;- read.csv(file = &quot;https://github.com/rensec/sasr08/raw/main/g_adj_list.csv&quot;) g_adj_list ## id age friend1 friend2 ## 1 1 20 2 4 ## 2 2 21 3 NA ## 3 3 25 1 NA ## 4 4 NA NA NA ## 5 5 21 NA NA Note that: The columns “friend1” and “friend2” could, for example, refer to “name generator” survey questions, where each node number in the column refers to a friend “nominated” by the node (respondent) in the corresponding row. In this case, the nodes can have at most two (outgoing) ties. This format allows for easy inclusion of node attributes as well, such as, in this case, the column “age”. Unfortunately, igraph does not have a function to directly import adjacency lists.2 The most convenient way to create a network object from these data, is to first transform them into an edge list, as this is a format for which igraph has an import function, such that we can turn it into a network object. To create an edge list, we first make the data long. g_elist_from_alist &lt;- g_adj_list g_elist_from_alist &lt;- select(g_elist_from_alist, id, friend1:friend2) # keep only the network variables (and id) g_elist_from_alist &lt;- melt(g_elist_from_alist, id.vars = &quot;id&quot;) # from the reshape2 package g_elist_from_alist ## id variable value ## 1 1 friend1 2 ## 2 2 friend1 3 ## 3 3 friend1 1 ## 4 4 friend1 NA ## 5 5 friend1 NA ## 6 1 friend2 4 ## 7 2 friend2 NA ## 8 3 friend2 NA ## 9 4 friend2 NA ## 10 5 friend2 NA To streamline this code a little bit, we could use the “pipe” operator (%&gt;%) which comes with the tidyverse package. This does exactly the same, but allows us to write the code more compactly. In RStudio, you can insert it easily using the CTRL-SHIFT-M keyboard shortcut (in Windows). g_elist_from_alist &lt;- g_adj_list %&gt;% select(id, friend1:friend2) %&gt;% # keep only the network variables (and id) melt( id.vars = &quot;id&quot;) # from the reshape2 package We could achieve the same result using the tidyr package (automatically loaded with tidyverse: g_adj_list %&gt;% # (we don&#39;t save it into an object as above this time, since we just want to show that the result is the same) select(id, friend1:friend2) %&gt;% #keep only the network variables (and id) pivot_longer(c(friend1, friend2)) ## # A tibble: 10 × 3 ## id name value ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 1 friend1 2 ## 2 1 friend2 4 ## 3 2 friend1 3 ## 4 2 friend2 NA ## 5 3 friend1 1 ## 6 3 friend2 NA ## 7 4 friend1 NA ## 8 4 friend2 NA ## 9 5 friend1 NA ## 10 5 friend2 NA To create an edge list we subsequently drop all missing values on “value” and do some housekeeping: g_elist_from_alist &lt;- g_elist_from_alist%&gt;% filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;id&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns g_elist_from_alist ## from to sourcevar ## 1 1 2 friend1 ## 2 2 3 friend1 ## 3 3 1 friend1 ## 4 1 4 friend2 We can now, once again, interpret each {from,to} combination as a directed edge (tie) from respondent to alter; in addition, sourcevar is an edge attribute indicating where in the adjacency list columns the alter was mentioned. Strictly speaking you don’t need the latter for a simple edge list, but it’s useful to keep in case you want to reverse the procedure. QUESTION: Besides being useful for data manipulation procedures, keeping the information in sourcevar could also be important for more substantive reasons. Can you think of such a reason? Now we can import this into a network object with an igraph function: g_from_alist &lt;- graph_from_data_frame(g_elist_from_alist) #This is a proper igraph graph object plot(g_from_alist) Note however, once more, that we lost the isolate! To include the isolate, we need to feed the function also the list of all the nodes, as we did before. However, in this case, we can also create the node list from the adjacency list data frame itself: nodelist &lt;- select(g_adj_list,id,age) g_from_alist &lt;- graph_from_data_frame(g_elist_from_alist, vertices = nodelist) #This is a proper igraph graph object plot(g_from_alist) That’s better! Note that besides the node IDs, we also include the age variable in the network object as a node attribute, such that we could use it in analyses based on the network object. Assignment: from the code snippets above, construct a complete “pipeline” to go from the adjacency list to the igraph object. Start from g_adj_list. Plot the resulting network. Store the code for later use. 1.2 The reverse direction: exporting from igraph objects Handling your network data as igraph objects is useful for social network analysis, but sometimes we also want to transform our data back from network objects to “regular” matrix objects or data frames. We briefly cover some of these cases here. Typically, we can use dedicated igraph functions for this purpose. 1.2.1 From igraph to adjacency matrix g_adj_matrix &lt;- as_adjacency_matrix(g, sparse = FALSE) g_adj_matrix ## 1 2 3 4 5 ## 1 0 1 0 1 0 ## 2 0 0 1 0 0 ## 3 1 0 0 0 0 ## 4 0 0 0 0 0 ## 5 0 0 0 0 0 We here specify sparse = FALSE because by default, as_adjacency_matrix() will return a “sparse matrix” (just run as_adjacenct_matrix(g) on your R console and see what comes out), which is a somewhat more efficient way of handling matrices with many zeroes. To demonstrate that we can recreate our original adjacency matrix however, we don’t want that here. To check whether the resulting matrix is indeed identical to what we originally read from a file we can do: all(g_adj_matrix == g_matrix) ## [1] TRUE 1.2.2 From igraph to edge list g_edgelist &lt;- igraph::as_data_frame(g_from_elist, what = &quot;edges&quot;) g_edgelist ## from to ## 1 1 2 ## 2 2 3 ## 3 3 1 ## 4 1 4 Note the use of the “namespace” “igraph::” here, to indicate that we need the igraph function here, not the function with the same name from the dplyr/tidyverse package Note that now, once more, we have lost our isolated node 5, as it is not included in the edge list! As before, we need a list of nodes in to our edge list to have a complete overview of the network, including any isolates. To get the nodes list, we could simply run: igraph::as_data_frame(g_from_elist, what = &quot;vertices&quot;) ## name age ## 1 1 20 ## 2 2 21 ## 3 3 25 ## 4 4 NA ## 5 5 21 1.2.3 From igraph to adjacency list edgelist_2 &lt;- igraph::as_data_frame(g_from_alist, what = &quot;edges&quot;) nodelist_2 &lt;- igraph::as_data_frame(g_from_alist, what = &quot;vertices&quot;) # Note the use of the &quot;namespace&quot; &quot;igraph::&quot; here, to indicate that we need the igraph function here, not the function with the same name from the dplyr/tidyverse package d &lt;- edgelist_2 %&gt;% rename(id = &quot;from&quot;) %&gt;% pivot_wider( id_cols = id, names_from = sourcevar, values_from = to ) %&gt;% merge(nodelist_2, by.x = &quot;id&quot;, by.y = &quot;name&quot;, all.y = TRUE ) %&gt;% relocate(age, .after = id) %&gt;% type_convert() #as_data_frame returns characters; this transforms it back to numeric ## ## ── Column specification ────────────────────────────────────────────────────────────────────────────────────────────── ## cols( ## id = col_double(), ## friend1 = col_double(), ## friend2 = col_double() ## ) d ## id age friend1 friend2 ## 1 1 20 2 4 ## 2 2 21 3 NA ## 3 3 25 1 NA ## 4 4 NA NA NA ## 5 5 21 NA NA …and we’re back! 1.3 Getting network data into R: the network package An alternative to igraph is the network package, which has its own type of network data object (as used by, for example, the sna and ergm packages), and its own set of functions for handling network data. Note that we’ve already loaded the network package at the start of the tutorial. We can import our data into a network object (using the edge list that we’ve created before) as follows: g_np &lt;- as.network(g_elist_from_alist, matrix.type = &quot;edgelist&quot;, vertices = nodelist) g_np ## Network attributes: ## vertices = 5 ## directed = TRUE ## hyper = FALSE ## loops = FALSE ## multiple = FALSE ## bipartite = FALSE ## total edges= 4 ## missing edges= 0 ## non-missing edges= 4 ## ## Vertex attribute names: ## age vertex.names ## ## Edge attribute names: ## sourcevar plot(g_np) We don’t discuss network in-depth for now; it suffices to say that the choice between igraph and network will typically depend on the specific needs of your research project. Both packages include a large set of functions for handling network data, but as igraph is a bit more comprehensive in terms of functions for network analysis, it tends to be somewhat more popular. There are also companion packages for network that allow various types of analyses, included in the statnet suite. Finally, for converting between network- and igraph- objects, look at intergraph. 1.4 Modifying networks in igraph We now turn back to igraph. Once we have our data wrapped into a network object, we can use igraph functions to make changes to the data. For example, we may remove a node: g_mod &lt;- delete_vertices(g,2) plot(g_mod) This simple operation illustrates the power of handling networks as network objects: teh igraph function delete_vertices() “understands” that removing a node from a network logically implies that also the edges connected to this node should be removed. If you would have to do this with, say, a raw edge list or adjacency list, it would be much more cumbersome! The same function also takes a vector of node IDs. For example, to remove all nodes with age = 21, we could do: g_mod &lt;- delete_vertices(g,which(V(g)$age == 21)) plot(g_mod) In the above code, we use the igraph function V() to get all vertices of the graph. QUESTION:: Write the code to remove all nodes from g for which age is missing. We have already seen the use of set_vertex_attr() to add node attributes, of V() to get all nodes. As an alternative to set_vertex_attr(), we can also use V() for the same purpose: V(g)$gender &lt;- c(&quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;other&quot;, &quot;male&quot;) g ## IGRAPH 1c7e4a3 DN-- 5 4 -- ## + attr: name (v/c), age (v/n), gender (v/c) ## + edges from 1c7e4a3 (vertex names): ## [1] 1-&gt;2 1-&gt;4 2-&gt;3 3-&gt;1 Similarly, we can use E() to access, add and modify edge attributes. We can also use functions that modify the entire graph. For example, we may use reverse() to reverse the direction of all edges: g_rev &lt;- reverse_edges(g) plot(g_rev) We can use union() to combine the edges of two graphs: g_union &lt;- igraph::union(g, g_rev) QUESTION: Before you run plot(g_union), think about what the resulting should look like. Thus, what could you use the combination of reverse() and union() for? A similar result could be produced with: g_undir &lt;- as_undirected(g) plot(g_undir) Realize however that conceptually, g_union and g_undir are different! QUESTION: What’s the difference? For more information on all the graph manipulation functions included in igraph, see the package’s website and, of course, the help pages in R. network is also designed for handling network data, but we focus on igraph here for simplicity. The idea is that once you are familiar with igraph, using the procedures in network is relatively straightforward.↩︎ Actually there is an igraph function ‘graph_from_adj_list()’, but this expects a different data structure than what we have here.↩︎ "],["basic-network-analysis-in-r.html", "2 Basic network analysis in R 2.1 Network level: a “five number summary” 2.2 Individual level: centrality", " 2 Basic network analysis in R In this tutorial we’ll use the igraph package to do some basic descriptive social network analysis. Obviously, we can only scratch the surface here, and many research project will require different analyses. Also, we do not cover visualization specifically. As an example network, we’ll use the famous “karate club” data studied by Zachary (1977), included with igraph. library(igraph) z &lt;- make_graph(&quot;Zachary&quot;) z ## IGRAPH 1e37432 U--- 34 78 -- Zachary ## + attr: name (g/c) ## + edges from 1e37432: ## [1] 1-- 2 1-- 3 1-- 4 1-- 5 1-- 6 1-- 7 1-- 8 1-- 9 1--11 1--12 ## [11] 1--13 1--14 1--18 1--20 1--22 1--32 2-- 3 2-- 4 2-- 8 2--14 ## [21] 2--18 2--20 2--22 2--31 3-- 4 3-- 8 3--28 3--29 3--33 3--10 ## [31] 3-- 9 3--14 4-- 8 4--13 4--14 5-- 7 5--11 6-- 7 6--11 6--17 ## [41] 7--17 9--31 9--33 9--34 10--34 14--34 15--33 15--34 16--33 16--34 ## [51] 19--33 19--34 20--34 21--33 21--34 23--33 23--34 24--26 24--28 24--33 ## [61] 24--34 24--30 25--26 25--28 25--32 26--32 27--30 27--34 28--34 29--32 ## [71] 29--34 30--33 30--34 31--33 31--34 32--33 32--34 33--34 plot(z) This looks like an undirected network, which we can verify using: is_directed(z) ## [1] FALSE 2.1 Network level: a “five number summary” A good starting point of any network analysis project is to look at some basic properties of the graph as a whole. While there are many potentially interesting properties, we’ll focus here on the the “five number summary” as suggested by Luke (2015). 2.1.1 Size Probably the most basic property of a network is its size, that is, the number of vertices and the number of edges (of course these are actually already two numbers, but well..). While igraph already reported them above (if you knew where to look), we can ask for these numbers specifically: vcount(z) ## [1] 34 ecount(z) ## [1] 78 2.1.2 Density The density of a network is the ratio of existing edges and the maximum possible number of edges that could exist, given the number of vertices. We can let R calculate it for us: edge_density(z) ## [1] 0.1390374 Obviously, we could already have calculated this ourselves, given that we already knew the number of edges and the number of vertices. QUESTION: How would you calculate density using ecount() and vcount()? If desired, we can also add such network-level results to the network object, for later use: z$density &lt;- edge_density(z) z ## IGRAPH 1e37432 U--- 34 78 -- Zachary ## + attr: name (g/c), density (g/n) ## + edges from 1e37432: ## [1] 1-- 2 1-- 3 1-- 4 1-- 5 1-- 6 1-- 7 1-- 8 1-- 9 1--11 1--12 ## [11] 1--13 1--14 1--18 1--20 1--22 1--32 2-- 3 2-- 4 2-- 8 2--14 ## [21] 2--18 2--20 2--22 2--31 3-- 4 3-- 8 3--28 3--29 3--33 3--10 ## [31] 3-- 9 3--14 4-- 8 4--13 4--14 5-- 7 5--11 6-- 7 6--11 6--17 ## [41] 7--17 9--31 9--33 9--34 10--34 14--34 15--33 15--34 16--33 16--34 ## [51] 19--33 19--34 20--34 21--33 21--34 23--33 23--34 24--26 24--28 24--33 ## [61] 24--34 24--30 25--26 25--28 25--32 26--32 27--30 27--34 28--34 29--32 ## [71] 29--34 30--33 30--34 31--33 31--34 32--33 32--34 33--34 ‘Density’ is now listed as one of the attributes of the object, where ‘g/n’ indicates that it is a graph-level attribute. 2.1.3 Components The number of components is the number of unconnected parts of the network (which may be parts consisting of one node, that is, isolates). The number of components in this network is, quite trivially, just one, but the way to get it is: count_components(z) ## [1] 1 2.1.4 Diameter (and distances) The diameter of a network is the “longest shortest path” in the network diameter(z) ## [1] 5 A related an much-studied property is the average shortest path length, that is, the average of all the shortest path over all pairs of vertices in the network. For example, this is the key indicator in the “small world phenomenon”. mean_distance(z) ## [1] 2.4082 2.1.5 Clustering Coefficient Clustering, or transitivity, relates to the extent to which triangles tend to be closed in the network, or put differently, to what extent neighbors of nodes tend to be connected themselves. There are many ways to quantify this tendency (which also differ for directed an undirected networks), and the transitivity() function covers many of them. Note that in the literature and elsewhere in the field, terms like ‘transitivity’ and ‘clustering’ are often used quite loosely, so it is always wise to look closely at the formal specifications (if provided) to know what is meant in a specific use case. We here compute what is most commonly known as the ‘clustering coefficient’. This computes, for each vertex, the proportion of the potential ties between the vertex’ neighbors that actually exist (in the ego networks literature, this is referred to as local density), and averages this over all vertices. transitivity(z, type=&quot;average&quot;) ## [1] 0.5879306 Interestingly, the specification of ‘average’ for the ‘type’ parameter is not explained in the igraph documentation, but this is what it does. 2.2 Individual level: centrality Moving to the individual (that is, node-level) measures, we concentrate here on centrality measures. Obviously, there are many other measures related to individual network position that may be relevant (and are included in igraph, see the reference manual). 2.2.1 Degree centrality The most straightforward measure of centrality is degree centrality, or simply the number of connections per node. We obtain it using the degree() function from igraph: degree(z) ## [1] 16 9 10 6 3 4 4 4 5 2 3 1 2 5 2 2 2 2 2 3 2 2 2 5 3 ## [26] 3 2 4 3 4 4 6 12 17 Because degree is an individual-level property, the result from the function is no longer a single number as before, but a vector of numbers, one for each node. Of course we can use this vector for further calculations: summary(degree(z)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 3.000 4.588 5.000 17.000 hist(degree(z)) (Note that there are of course much nicer and better ways to analyze and visualize distributions like this, but that is not the point of this tutorial.) In many other cases, we’d want to keep the individual-level results on centrality and add them to the network object for later use: V(z)$degree &lt;- degree(z) We may, for example, want to use it in a plot: #We add + 8 to degree to avoid that the lowest-degree nodes become really small and specify margin = -0.1 to reduce the whitespace around the plot plot(z, vertex.size = V(z)$degree+8, margin= -0.1) Finally, if you run ?degree() on your console, you’ll note that the function has a number of other useful options. For example, we can also extract the degree of a specific vertex: degree(z, v = 3) ## [1] 10 Furthermore, for directed networks, you can also specify whether you want indegree, outdegree, or the total degree (but that does not apply to our undirected example network). 2.2.2 Betweenness centrality A fancier centrality measure is betweenness centrality, which relies on the shortest paths between all pairs of vertices to assess to what extent nodes sit on shortest paths between other nodes. betweenness(z) ## [1] 231.0714286 28.4785714 75.8507937 6.2880952 0.3333333 15.8333333 ## [7] 15.8333333 0.0000000 29.5293651 0.4476190 0.3333333 0.0000000 ## [13] 0.0000000 24.2158730 0.0000000 0.0000000 0.0000000 0.0000000 ## [19] 0.0000000 17.1468254 0.0000000 0.0000000 0.0000000 9.3000000 ## [25] 1.1666667 2.0277778 0.0000000 11.7920635 0.9476190 1.5428571 ## [31] 7.6095238 73.0095238 76.6904762 160.5515873 We again add it to the network object. This time, we use set_vertex_attr() rather than V() just to demonstrate that this may work better in a “pipeline” workflow: z &lt;- z %&gt;% set_vertex_attr( name = &quot;betweenness&quot;, value = betweenness(z) ) 2.2.3 Closeness centrality Finally, we add closeness centrality, which also relies on shortest paths, but instead assesses how close each node is to the other nodes. V(z)$closeness &lt;- closeness(z) "],["tut_first_knecht.html", "3 Introducing the Knecht data 3.1 A first look at the data 3.2 Assignment", " 3 Introducing the Knecht data In this tutorial, we take some real network data that we will use throughout the course. The goal is to import the data, and perform some data management tasks as we’ve done in the previous tutorials, as well as some basic analysis, but now with real data instead of “toy data”. In the first part of the tutorial, we’ll have a first look at the data and select some data to work with. The second part is an assignment in which you apply your knowledge from the previous tutorials to these data. First we need to load some packages: library(igraph) library(haven) # to read Stata files library(reshape2) library(tidyverse) 3.1 A first look at the data The data we are using is the longitudinal dataset collected by Andrea Knecht for her dissertation at Utrecht University in 2003-2004. Using questionnaires, she collected data from 3171 students in 126 first-grade classes of 14 secondary schools in the Netherlands. The students were surveyed at three-month intervals one the academic year. The survey included (among many other things) name generator questions for friendship networks, support networks, interaction networks, and a number of other networks. You can find the data file for one wave on Blackboard, under Course Content/data. Download this file and save it in the same directory as your R-script. We first load the data set (note the use of the function to import Stata’s *.dta format): PupilsWaveV &lt;- read_dta(file = &quot;PupilsWaveV.dta&quot;) The variables schoolnr and namenr represent, respectively, classes (in schools) and pupils in classes. QUESTION: Have a close look at these two variables, comparing the namenr values for different classes (just eyeballing the data should be sufficient). What do you notice? To keep things manageable for now, we select only one class: class12b &lt;- PupilsWaveV %&gt;% filter(schoolnr == &quot;12b&quot;) # keep only one class The name generator question for “best friends” asked the pupils to nominate up to 12 of their best friends in class; the resulting nominations are stored in the variables friend1, friend2,… friend12. This is the network we will work with in this tutorial (but there are many other interesting name generators in the data set!). 3.2 Assignment In the following assignment, you are asked to perform a first descriptive network analysis of the friendship network in class 12b, using the techniques in the tutorials so far. Please complete the following tasks: Import the data into an igraph network object. For the network, use the ‘friend..’ variables; for node attributes, include age and gender. TIP: First think carefully about what format the data are in, and which corresponding procedure from the ones discussed in the tutorials you’d need to import the data properly. Establish whether, from an empirical perspective, this is a directed or an undirected network. First, think about what it should be, given the data collection method, and then verify that this is indeed correct in the data. Make a first visualization of the network. Make a ‘five number summary’ of the network. Test the hypothesis that girls have higher degree than boys in this network. Visualize the network again, this time making vertex size dependent on degree, and vertex color on gender (the relevant parameter is vertex.color). What strikes you about this network? "],["networks-as-causes-spatial-regression-analysis.html", "4 Networks as causes: Spatial regression analysis 4.1 Constructing a Spatial Weight Matrix 4.2 Linear Regression Analysis 4.3 Spatial Analysis 4.4 Knecht Assignment", " 4 Networks as causes: Spatial regression analysis 4.1 Constructing a Spatial Weight Matrix To estimate spatial models, we need two packages: spdep package, and spatialreg package. Install these packages first and then load them using the library command. library(spdep) #We need the spdep package for the spatial weight matrix and for the Moran&#39;s I test library(spatialreg) #We need the spatialreg package for the spatial lag and spatial error models We continue with the example from the lecture: we are interested in whether household income has an effect on the crime rate using neighborhood data. We control for house prices as house prices are correlated with both household income and crime rates. We use Anselin’s Columbus data for crime rates of neighborhoods in Columbus, Ohio, USA in 1980. The codebook can be found here: https://geodacenter.github.io/data-and-lab/columbus/ The data are already part of the spdep package and we obtain the data as follows data(columbus) mydata &lt;- columbus Instead of using the tedious dollar sign every time we type a variable, we can attach the data and just type the variable: attach(mydata) There are 49 neighborhoods in the data. Our dependent variable is the crime rate, measured as residential burglaries and vehicle thefts per 1000 households: CRIME. Our independent variable is the household income in 1,000 USD: INC. Our control variable is the housing value in 1,000 USD: HOVAL. Col.gal.nb provides an adjacency list of neighbors. We give it a better name: neighbors &lt;- col.gal.nb We check the class of the adjacency list: class(neighbors) ## [1] &quot;nb&quot; Note that it is an ‘nb’ or ‘neighborhood’ object. In spatial regression analysis, you need a so-called ‘weighted list - listw’ object. To arrive to a listw object, often it is easiest to first convert a dataframe to ‘nb’. You can do this simply with the command class(dataframe) &lt;- “nb”. And then, we can use nb2listw(nblist). Another approach (which is more suitable when having isolates) is to first make an adjacency matrix. Then you can use mat2listw(adjacencymatrix). In this case, however, we already have an nb object. So the only thing we need to do is to go to a listw object. We specify style ‘W’ to row-standardize: listw &lt;- nb2listw(neighbors, style = &quot;W&quot;) summary(listw) ## Characteristics of weights list object: ## Neighbour list object: ## Number of regions: 49 ## Number of nonzero links: 230 ## Percentage nonzero weights: 9.579342 ## Average number of links: 4.693878 ## Link number distribution: ## ## 2 3 4 5 6 7 8 9 10 ## 7 7 13 4 9 6 1 1 1 ## 7 least connected regions: ## 1005 1008 1045 1047 1049 1048 1015 with 2 links ## 1 most connected region: ## 1017 with 10 links ## ## Weights style: W ## Weights constants summary: ## n nn S0 S1 S2 ## W 49 2401 49 23.48489 204.6687 We see that an average region has about 5 neighbors. 4.2 Linear Regression Analysis We now turn to a linear regression model using OLS. ALWAYS START WITH THE EASIEST MODEL! The easiest model is more often than not sufficient for the main analyses. Before we estimate the model, let’s first summarize the variables: summary(CRIME) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.1783 20.0485 34.0008 35.1288 48.5855 68.8920 summary(INC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4.477 9.963 13.380 14.375 18.324 31.070 summary(HOVAL) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 17.90 25.70 33.50 38.44 43.30 96.40 Nothing seems out of the ordinary. Now we would like to plot the neighborhoods to visualize the network. Coordinates of each neighborhood are provided in ‘coords’. plot(neighbors, coords) We observe that some neighborhoods serve as bridges between neighborhoods that are distant from each other. Let’s now run a linear regression model: olsreg &lt;- lm(CRIME ~ INC + HOVAL) summary(olsreg) ## ## Call: ## lm(formula = CRIME ~ INC + HOVAL) ## ## Residuals: ## Min 1Q Median 3Q Max ## -34.418 -6.388 -1.580 9.052 28.649 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 68.6190 4.7355 14.490 &lt; 2e-16 *** ## INC -1.5973 0.3341 -4.780 1.83e-05 *** ## HOVAL -0.2739 0.1032 -2.654 0.0109 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.43 on 46 degrees of freedom ## Multiple R-squared: 0.5524, Adjusted R-squared: 0.5329 ## F-statistic: 28.39 on 2 and 46 DF, p-value: 9.341e-09 Higher household income and higher housing values lead to a significantly lower crime rate. 4.3 Spatial Analysis 4.3.1 Moran’s I test While estimating the linear regression model, we did not take the spatial dependence into account and our hypothesis tests may lead to erroneous conclusions. To test whether we need spatial analysis, we now run a Moran’s I test: moran.test(CRIME, listw) ## ## Moran I test under randomisation ## ## data: CRIME ## weights: listw ## ## Moran I statistic standard deviate = 5.3427, p-value = 4.578e-08 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.485770914 -0.020833333 0.008991121 p-value is very small so we reject the null hypothesis of no spatial dependence. We should not use a linear regression, but we should use a spatial model instead. 4.3.2 Lagrange multiplier tests for spatial lag and spatial error dependencies Now we know that we should use a spatial model, the question is which model. To distinguish between the spatial lag and spatial error model, we run a Lagrange multiplier test: lm.RStests(olsreg, listw, test=c(&quot;LMlag&quot;, &quot;LMerr&quot;)) ## ## Rao&#39;s score (a.k.a Lagrange multiplier) diagnostics for spatial ## dependence ## ## data: ## model: lm(formula = CRIME ~ INC + HOVAL) ## test weights: listw ## ## RSlag = 7.8557, df = 1, p-value = 0.005066 ## ## ## Rao&#39;s score (a.k.a Lagrange multiplier) diagnostics for spatial ## dependence ## ## data: ## model: lm(formula = CRIME ~ INC + HOVAL) ## test weights: listw ## ## RSerr = 4.6111, df = 1, p-value = 0.03177 We reject both hypotheses. It appears that we should use both a spatial lag and a spatial error model. This shows that specification tests are far from perfect and that you should primarily be guided by the theory! 4.3.3 Spatial lag model We now estimate a spatial lag model. It is good practice to start with a spatial lag model first, then the spatial error model, and then add increasing complexity by estimating other models. slm &lt;- lagsarlm(CRIME ~ INC + HOVAL, data = mydata, listw, Durbin = &quot;FALSE&quot;) summary(slm) ## ## Call:lagsarlm(formula = CRIME ~ INC + HOVAL, data = mydata, listw = listw, ## Durbin = &quot;FALSE&quot;) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.4497093 -5.4565567 0.0016387 6.7159553 24.7107978 ## ## Type: lag ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 46.851431 7.314754 6.4051 1.503e-10 ## INC -1.073533 0.310872 -3.4533 0.0005538 ## HOVAL -0.269997 0.090128 -2.9957 0.0027381 ## ## Rho: 0.40389, LR test value: 8.4179, p-value: 0.0037154 ## Asymptotic standard error: 0.12071 ## z-value: 3.3459, p-value: 0.00082027 ## Wald statistic: 11.195, p-value: 0.00082027 ## ## Log likelihood: -183.1683 for lag model ## ML residual variance (sigma squared): 99.164, (sigma: 9.9581) ## Number of observations: 49 ## Number of parameters estimated: 5 ## AIC: 376.34, (AIC for lm: 382.75) ## LM test for residual autocorrelation ## test value: 0.19184, p-value: 0.66139 Again a significantly negative effect of household income and housing values on the crime rate, even after accounting for the crime feedback loop in neighboring neighborhoods. Coefficients are very similar to the OLS coefficients. This is often the case given that OLS coefficients are most often still unbiased. The spatial parameter rho is positive and significant showing dependence: crime in neighboring neighborhoods increases crime in the focal neighborhood, even after accounting for income and housing value of the focal neighborhood. We now turn to the direct and indirect effects. For this purpose, we follow the approximation method by Lesage and Pase (2009) . We specify ‘zstats = TRUE’ to obtain p-values. We use a simulation with 20000 iterations to obtain p-values, and we set the “seed” to make sure that stochastic process of the simulation starts from the same starting values every time, and therefore produces the same result every time. set.seed(125274) im&lt;-impacts(slm, listw = listw, zstats=TRUE, R=20000) sums&lt;-summary(im, zstats=T) data.frame(sums$res) ## direct indirect total ## 1 -1.1225156 -0.6783818 -1.8008973 ## 2 -0.2823163 -0.1706152 -0.4529315 data.frame(sums$pzmat) ## Direct Indirect Total ## INC 0.0003640712 0.05678103 0.001252427 ## HOVAL 0.0026442807 0.10773182 0.011736824 The results indicate that, although both total effects are significant, they are mainly driven by direct effects. When we look at the direct effects, we observe that an increase in household income and an increase in housing value in a neighborhood significantly reduce crime in that same neighborhood. When we look at the indirect effects, we observe that an increase in household income and an increase in housing value in a neighboring neighborhood reduce crime in the focal neighborhood. However, the indirect impacts are not significant. When we look at the total effect, we observe that if we increase household income and the housing value in all neighborhoods simultaneously, the average country-wide crime would significantly decrease. 4.3.4 Spatial error model sem &lt;- errorsarlm(CRIME ~ INC + HOVAL, data = mydata, listw, Durbin = FALSE) summary(sem) ## ## Call:errorsarlm(formula = CRIME ~ INC + HOVAL, data = mydata, listw = listw, ## Durbin = FALSE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -34.45950 -6.21730 -0.69775 7.65256 24.23631 ## ## Type: error ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 61.053618 5.314875 11.4873 &lt; 2.2e-16 ## INC -0.995473 0.337025 -2.9537 0.0031398 ## HOVAL -0.307979 0.092584 -3.3265 0.0008794 ## ## Lambda: 0.52089, LR test value: 6.4441, p-value: 0.011132 ## Asymptotic standard error: 0.14129 ## z-value: 3.6868, p-value: 0.00022713 ## Wald statistic: 13.592, p-value: 0.00022713 ## ## Log likelihood: -184.1552 for error model ## ML residual variance (sigma squared): 99.98, (sigma: 9.999) ## Number of observations: 49 ## Number of parameters estimated: 5 ## AIC: 378.31, (AIC for lm: 382.75) Again a significantly negative effect of household income and housing values on the crime rate. The spatial parameter lambda is positive and significant showing that the unobserved characteristics of the neighbors influence crime of the focal neighborhood. 4.3.5 Spatial autoregressive combined model sac &lt;- sacsarlm(CRIME ~ INC + HOVAL, data = mydata, listw, Durbin = FALSE) summary(sac) ## ## Call:sacsarlm(formula = CRIME ~ INC + HOVAL, data = mydata, listw = listw, ## Durbin = FALSE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.1121 -4.6324 -0.3040 7.0306 24.6929 ## ## Type: sac ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 49.051432 10.054986 4.8783 1.07e-06 ## INC -1.068781 0.332839 -3.2111 0.001322 ## HOVAL -0.283114 0.091526 -3.0933 0.001980 ## ## Rho: 0.35326 ## Asymptotic standard error: 0.19669 ## z-value: 1.796, p-value: 0.072494 ## Lambda: 0.13199 ## Asymptotic standard error: 0.29905 ## z-value: 0.44138, p-value: 0.65894 ## ## LR test value: 8.6082, p-value: 0.013513 ## ## Log likelihood: -183.0731 for sac model ## ML residual variance (sigma squared): 99.423, (sigma: 9.9711) ## Number of observations: 49 ## Number of parameters estimated: 6 ## AIC: 378.15, (AIC for lm: 382.75) Similar results, but rho and lambda are now not significant. 4.3.6 Spatial Durbin model sdm &lt;- lagsarlm(CRIME ~ INC + HOVAL, data = mydata, listw, Durbin = TRUE) summary(sdm) ## ## Call:lagsarlm(formula = CRIME ~ INC + HOVAL, data = mydata, listw = listw, ## Durbin = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.15904 -6.62594 -0.39823 6.57561 23.62757 ## ## Type: mixed ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 45.592893 13.128679 3.4728 0.0005151 ## INC -0.939088 0.338229 -2.7765 0.0054950 ## HOVAL -0.299605 0.090843 -3.2980 0.0009736 ## lag.INC -0.618375 0.577052 -1.0716 0.2838954 ## lag.HOVAL 0.266615 0.183971 1.4492 0.1472760 ## ## Rho: 0.38251, LR test value: 4.1648, p-value: 0.041272 ## Asymptotic standard error: 0.16237 ## z-value: 2.3557, p-value: 0.018488 ## Wald statistic: 5.5493, p-value: 0.018488 ## ## Log likelihood: -182.0161 for mixed model ## ML residual variance (sigma squared): 95.051, (sigma: 9.7494) ## Number of observations: 49 ## Number of parameters estimated: 7 ## AIC: 378.03, (AIC for lm: 380.2) ## LM test for residual autocorrelation ## test value: 0.101, p-value: 0.75063 We see that the results are similar and the lags are not significant. 4.3.7 Spatial Durbin error model sdem &lt;- errorsarlm(CRIME ~ INC + HOVAL, data = mydata, listw, Durbin = TRUE) summary(sdem) ## ## Call:errorsarlm(formula = CRIME ~ INC + HOVAL, data = mydata, listw = listw, ## Durbin = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.02060 -6.68585 -0.15142 6.51557 24.18199 ## ## Type: error ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 73.258655 8.528044 8.5903 &lt; 2.2e-16 ## INC -1.069530 0.324719 -3.2937 0.0009887 ## HOVAL -0.280344 0.091809 -3.0535 0.0022615 ## lag.INC -1.196774 0.568968 -2.1034 0.0354297 ## lag.HOVAL 0.146758 0.200872 0.7306 0.4650196 ## ## Lambda: 0.37613, LR test value: 3.7313, p-value: 0.053403 ## Asymptotic standard error: 0.16554 ## z-value: 2.2721, p-value: 0.023079 ## Wald statistic: 5.1626, p-value: 0.023079 ## ## Log likelihood: -182.2329 for error model ## ML residual variance (sigma squared): 96.022, (sigma: 9.7991) ## Number of observations: 49 ## Number of parameters estimated: 7 ## AIC: 378.47, (AIC for lm: 380.2) Results are again similar, but now the lag of household income is significant. 4.3.8 General nested model gnm &lt;- sacsarlm(CRIME ~ INC + HOVAL, data = mydata, listw, Durbin = TRUE) summary(gnm) ## ## Call:sacsarlm(formula = CRIME ~ INC + HOVAL, data = mydata, listw = listw, ## Durbin = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.36766 -6.68648 -0.44936 6.38015 23.80258 ## ## Type: sacmixed ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 50.35976 63.33587 0.7951 0.426542 ## INC -0.96203 0.43539 -2.2096 0.027135 ## HOVAL -0.29462 0.10275 -2.8674 0.004139 ## lag.INC -0.72000 1.61312 -0.4463 0.655352 ## lag.HOVAL 0.24470 0.26967 0.9074 0.364187 ## ## Rho: 0.31731 ## Asymptotic standard error: 0.87681 ## z-value: 0.36189, p-value: 0.71743 ## Lambda: 0.090483 ## Asymptotic standard error: 1.0184 ## z-value: 0.088845, p-value: 0.92921 ## ## LR test value: 10.756, p-value: 0.029453 ## ## Log likelihood: -181.9994 for sacmixed model ## ML residual variance (sigma squared): 95.975, (sigma: 9.7967) ## Number of observations: 49 ## Number of parameters estimated: 8 ## AIC: 380, (AIC for lm: 382.75) Similar results again. 4.4 Knecht Assignment We are interested in whether there are sex differences in homework. Open the dataset “PupilsWaveV.dta”. Estimate a linear regression model of doing homework (acthomew) on sex (sex) while controlling for age (age). For this purpose, reverse the scale of acthomew so a higher value means more likely to do homework. Also, reverse the coding of sex and create a dummy variable so 1 is female and 0 is male. This is more in line with the literature. Estimate a multilevel linear model where you take class characteristics into account. In addition to gender differences, we are now also interested in whether peers influence one’s homework behavior. From now on consider only Class 12b. Construct an adjacency matrix of best friends. Construct a row-standardized spatial weight matrix as a weights list object. Set the option ‘zero.policy’ to TRUE because you have isolates. Conduct and interpret the Moran’s I test and the Lagrange multiplier tests. For the Lagrange multiplier tests, make sure you estimate a linear regression on Class 12b, not on the entire dataset. Estimate a SLM and the impacts. Interpret the results. Estimate a SEM and a SAC. Interpret the results. Estimate a SDM, SDEM, and GNM. Interpret the results. What is your conclusion after interpreting all these models? "],["exponential-random-graphs-modeling.html", "5 Exponential Random Graphs Modeling 5.1 Data preparation 5.2 Model estimation 5.3 Goodness of fit 5.4 Further resources on ERGMs", " 5 Exponential Random Graphs Modeling In this tutorial, we look at some basic ERGM using R. library(network) library(intergraph) library(sna) library(igraph) library(ergm) library(tidyverse) library(haven) 5.1 Data preparation We’ll work with the same single class (“12b”) from the Knecht data as before. To keep things very concise here, we simply load an igraph network object that we’ve saved to disk before. load(url(&quot;https://github.com/rensec/sasr08/raw/main/classnet.rdata&quot;)) summary(classnet) ## IGRAPH 963ef71 DN-- 26 91 -- ## + attr: name (v/c), sex (v/n), age (v/n), sourcevar (e/c) However, for exponential random graph modeling, we’ll actually need network objects from the network class (that is, as generated by the network package). For this, we’ll use the intergraph package, already loaded above. Unfortunately, network does not handle factor variables, so we first need to convert ‘sex’ to a numeric variable. V(classnet)$sex &lt;-as.numeric(V(classnet)$sex) g &lt;- asNetwork(classnet) g ## Network attributes: ## vertices = 26 ## directed = TRUE ## hyper = FALSE ## loops = FALSE ## multiple = FALSE ## bipartite = FALSE ## total edges= 91 ## missing edges= 0 ## non-missing edges= 91 ## ## Vertex attribute names: ## age sex vertex.names ## ## Edge attribute names: ## sourcevar The alternative approach would be to load the original data set, filter out the class, prepare the data as an edge list and node list as we’ve done before, and then import it directly into a network object using one of the as.network...() function from the network package. gplot(g, vertex.col=g %v% &quot;sex&quot;*2) Looks like we have some gender homophily going on here, as well as a lot of reciprocity! With ERGM, we can test this statistically. 5.2 Model estimation Now let’s estimate a simple model. First we test the hypothesis that ties are likely to be reciprocated. In this case we add, besides the “edges” term, the “mutual” term, which indicates the number of reciprocated ties. M1.g&lt;-ergm(g ~ edges + mutual ) ## Starting maximum pseudolikelihood estimation (MPLE): ## Obtaining the responsible dyads. ## Evaluating the predictor and response matrix. ## Maximizing the pseudolikelihood. ## Finished MPLE. ## Starting Monte Carlo maximum likelihood estimation (MCMLE): ## Iteration 1 of at most 60: ## Warning: &#39;glpk&#39; selected as the solver, but package &#39;Rglpk&#39; is not available; ## falling back to &#39;lpSolveAPI&#39;. This should be fine unless the sample size and/or ## the number of parameters is very big. ## 1 ## Optimizing with step length 1.0000. ## The log-likelihood improved by 0.0050. ## Convergence test p-value: 0.0001. Converged with 99% confidence. ## Finished MCMLE. ## Evaluating log-likelihood at the estimate. Fitting the dyad-independent submodel... ## Bridging between the dyad-independent submodel and the full model... ## Setting up bridge sampling... ## Using 16 bridges: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 . ## Bridging finished. ## ## This model was fit using MCMC. To examine model diagnostics and check ## for degeneracy, use the mcmc.diagnostics() function. summary(M1.g) ## Call: ## ergm(formula = g ~ edges + mutual) ## ## Monte Carlo Maximum Likelihood Results: ## ## Estimate Std. Error MCMC % z value Pr(&gt;|z|) ## edges -2.7125 0.1825 0 -14.866 &lt;1e-04 *** ## mutual 3.2065 0.3972 0 8.072 &lt;1e-04 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Null Deviance: 901.1 on 650 degrees of freedom ## Residual Deviance: 453.8 on 648 degrees of freedom ## ## AIC: 457.8 BIC: 466.8 (Smaller is better. MC Std. Err. = 0.7482) Indeed, we find a positive and significant effect for the number of reciprocated ties. Now let’s add the homophily effect (nodematch), as well as a gender differential effect (nodefactor): M2.g&lt;-ergm(g ~ edges + mutual + nodefactor(&quot;sex&quot;, levels = 2) + nodematch(&quot;sex&quot; )) summary(M2.g) ## Call: ## ergm(formula = g ~ edges + mutual + nodefactor(&quot;sex&quot;, levels = 2) + ## nodematch(&quot;sex&quot;)) ## ## Monte Carlo Maximum Likelihood Results: ## ## Estimate Std. Error MCMC % z value Pr(&gt;|z|) ## edges -3.7294 0.3106 0 -12.008 &lt;1e-04 *** ## mutual 2.7813 0.4242 0 6.557 &lt;1e-04 *** ## nodefactor.sex.2 0.1970 0.1197 0 1.645 0.1 ## nodematch.sex 1.4871 0.2967 0 5.013 &lt;1e-04 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Null Deviance: 901.1 on 650 degrees of freedom ## Residual Deviance: 415.1 on 646 degrees of freedom ## ## AIC: 423.1 BIC: 441 (Smaller is better. MC Std. Err. = 0.6432) Indeed, we find a positive effect of gender homophily. We do not find that either boys or girls tend to have more ties than the other. 5.3 Goodness of fit Finally, let’s look at goodness of fit: M2.g.gof &lt;- gof(M2.g) M2.g.gof ## ## Goodness-of-fit for in-degree ## ## obs min mean max MC p-value ## idegree0 0 0 0.58 3 1.00 ## idegree1 4 0 2.28 7 0.38 ## idegree2 7 1 4.76 12 0.48 ## idegree3 4 1 5.74 11 0.56 ## idegree4 1 1 5.51 10 0.04 ## idegree5 6 0 3.77 11 0.34 ## idegree6 1 0 1.99 6 0.76 ## idegree7 3 0 0.89 3 0.04 ## idegree8 0 0 0.43 2 1.00 ## idegree9 0 0 0.03 1 1.00 ## idegree10 0 0 0.01 1 1.00 ## idegree11 0 0 0.01 1 1.00 ## ## Goodness-of-fit for out-degree ## ## obs min mean max MC p-value ## odegree0 1 0 0.43 3 0.74 ## odegree1 4 0 2.04 7 0.32 ## odegree2 4 0 4.94 11 0.86 ## odegree3 5 2 6.21 13 0.82 ## odegree4 6 2 5.63 11 0.90 ## odegree5 3 0 3.49 10 1.00 ## odegree6 0 0 1.87 6 0.28 ## odegree7 1 0 0.96 5 1.00 ## odegree8 1 0 0.36 2 0.58 ## odegree9 0 0 0.04 1 1.00 ## odegree10 1 0 0.03 1 0.06 ## ## Goodness-of-fit for edgewise shared partner ## ## obs min mean max MC p-value ## esp.OTP0 19 34 49.51 63 0.00 ## esp.OTP1 24 12 30.91 46 0.36 ## esp.OTP2 27 0 9.52 29 0.02 ## esp.OTP3 14 0 1.73 11 0.00 ## esp.OTP4 6 0 0.24 7 0.02 ## esp.OTP5 1 0 0.08 3 0.12 ## esp.OTP6 0 0 0.01 1 1.00 ## ## Goodness-of-fit for minimum geodesic distance ## ## obs min mean max MC p-value ## 1 91 65 92.00 115 0.90 ## 2 104 102 197.03 270 0.02 ## 3 80 116 193.41 249 0.00 ## 4 57 34 94.48 151 0.10 ## 5 48 0 30.10 84 0.40 ## 6 18 0 8.51 50 0.34 ## 7 5 0 2.24 32 0.30 ## 8 0 0 0.56 16 1.00 ## 9 0 0 0.07 5 1.00 ## 10 0 0 0.01 1 1.00 ## Inf 247 0 31.59 252 0.02 ## ## Goodness-of-fit for model statistics ## ## obs min mean max MC p-value ## edges 91 65 92.00 115 0.90 ## mutual 28 19 28.45 41 0.90 ## nodefactor.sex.2 58 34 58.17 90 0.96 ## nodematch.sex 79 56 79.53 101 1.00 This looks OK for the model statistics, but less so for the for network statistics not in the model. Let’s have a closer look at those: plot(M2.g.gof) Indeed, some of these are quite off, indicating that we might want to include some other effects in the model. Indeed, for directed networks, it is common to include at least some parameters related to degree, reciprocity, and something related to triadic closure. The exact choice of effects is not trivial though and may lead to computational complications, so we leave it at this for now. 5.4 Further resources on ERGMs For further introductions to ERGM, we suggest this tutorial by the Statnet team and this tutorial by Rawlings et al. The latter in particular has an informative illustration of the inclusion of triadic effects and the computational issues involved. Also helpful is this short list of common ERGM terms. A longer list is here. "],["a-deeper-dive-into-data-handling-complications-in-name-generator-data.html", "6 A deeper dive into data handling: complications in name generator data 6.1 The case of the missing ego 6.2 Double mentions 6.3 Multiple networks 6.4 Dyads-as-cases", " 6 A deeper dive into data handling: complications in name generator data In a previous tutorial, we’ve covered processing ‘adjacency list’ data, as typically generated by surveys with name generator questions, as network data. With real-life data, such data sets often have quirks that can create havoc in your data processing procedures if you’re not carefull. In the earlie tutorial, we already discussed one such quirk, namely the presences of isolates. In this tutorial, we cover two more challenges: The presence of alters who are missing as respondents (egos); The processing of multiple subnetworks (in our scenario: school classes) at the same time. Let’s get started. For practice, we use a toy dataset that was designed for looking just like the Knecht data (but smaller). url1 &lt;- &quot;https://github.com/rensec/sasr08/raw/main/toy_name_generator_data.csv&quot; df &lt;- read.csv(file = url1) table(df$schoolnr) ## ## 1a 2b ## 5 5 df ## schoolnr namenr age friend1 friend2 ## 1 1a 1 20 2 4 ## 2 1a 2 21 3 NA ## 3 1a 3 25 1 NA ## 4 1a 4 NA NA NA ## 5 1a 5 21 NA NA ## 6 2b 1 22 2 3 ## 7 2b 2 24 1 3 ## 8 2b 3 NA NA 4 ## 9 2b 4 21 2 5 ## 10 2b 5 20 6 NA 6.1 The case of the missing ego Let’s start with importing one class, as before: cls &lt;- &quot;1a&quot; edge_list &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr, friend1:friend2) %&gt;% melt(id.vars = &quot;namenr&quot;) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns edge_list ## from to sourcevar ## 1 1 2 friend1 ## 2 2 3 friend1 ## 3 3 1 friend1 ## 4 1 4 friend2 nodelist &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr,age) g1a &lt;- graph_from_data_frame(edge_list, vertices = nodelist) plot(g1a) So far, so good. Now let’s try with the other class: cls &lt;- &quot;2b&quot; edge_list &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr, friend1:friend2) %&gt;% melt(id.vars = &quot;namenr&quot;) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns edge_list ## from to sourcevar ## 1 1 2 friend1 ## 2 2 1 friend1 ## 3 4 2 friend1 ## 4 5 6 friend1 ## 5 1 3 friend2 ## 6 2 3 friend2 ## 7 3 4 friend2 ## 8 4 5 friend2 nodelist &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr,age) g2b &lt;- graph_from_data_frame(edge_list, vertices = nodelist) ## Error in graph_from_data_frame(edge_list, vertices = nodelist): Some vertex names in edge list are not listed in vertex data frame Problem: Now this leads to an error, as there is a vertex nominated as friend who is not in the data as an ‘ego’. The igraph function graph_from_data_frame() does not allow this. QUESTION: What is a plausible data collection scenario under which this could happen? Solution: We need to fix the node list to include this missing vertex. First let’s create a list of all the vertices that appear in the edge list: all_vertices &lt;- append(edge_list$from, edge_list$to) Then, we remove duplicates: all_vertices &lt;- unique(all_vertices) %&gt;% as.data.frame() %&gt;% rename(namenr = &quot;.&quot;) Next, we create a node list that includes all the vertices, by combining the list of nodes from the original data set with the list of vertices from the edge list. We do this by merging the two data sets, using the merge() function. nodelist &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr,age, schoolnr) %&gt;% merge(all_vertices, by = &quot;namenr&quot;, all.y = T, all.x = T) nodelist ## namenr age schoolnr ## 1 1 22 2b ## 2 2 24 2b ## 3 3 NA 2b ## 4 4 21 2b ## 5 5 20 2b ## 6 6 NA &lt;NA&gt; We now have a node list that includes all the nodes. Obviously, ‘age’ is missing for node 6 in these data, as node 6 was not included as a respondent in the data in the first place. However, ‘schoolnr’ is also missing, even if we know that node 6 was in this class too. So let’s fix that: nodelist &lt;- nodelist %&gt;% replace_na(list(schoolnr = cls)) nodelist ## namenr age schoolnr ## 1 1 22 2b ## 2 2 24 2b ## 3 3 NA 2b ## 4 4 21 2b ## 5 5 20 2b ## 6 6 NA 2b g2b &lt;- graph_from_data_frame(edge_list, vertices = nodelist) plot(g2b) 6.2 Double mentions Let’s look at a variation of our toy data set, called toy_data_generator_data_2.csv. url1 &lt;- &quot;toy_name_generator_data_2.csv&quot; df2 &lt;- read.csv(file = url1) table(df2$schoolnr) ## ## 3a ## 5 df2 ## schoolnr namenr age friend1 friend2 ## 1 3a 1 20 2 4 ## 2 3a 2 21 3 3 ## 3 3a 3 25 1 NA ## 4 3a 4 NA NA NA ## 5 3a 5 21 NA NA We create an edge list: edge_list_3a &lt;- df2 %&gt;% select(namenr, friend1:friend2) %&gt;% melt(id.vars = &quot;namenr&quot;) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns edge_list_3a ## from to sourcevar ## 1 1 2 friend1 ## 2 2 3 friend1 ## 3 3 1 friend1 ## 4 1 4 friend2 ## 5 2 3 friend2 …and the nodes list: nodelist_3a &lt;- df2 %&gt;% select(namenr,age) g3a &lt;- graph_from_data_frame(edge_list_3a, vertices = nodelist_3a) plot(g3a) Now we see something strange: there are two edges from node 2 to node 3. This even leads to problems when we try to create a network object using the network package: g3a_nw &lt;- as.network(edge_list_3a, matrix.type = &quot;edgelist&quot;, vertices = nodelist_3a) ## Error: `multiple` is `FALSE`, but `x` contains parallel edges. ## The following rows in `x` are duplicated: ## - `x[5, ]` The problem here is that node two nominates the same alter (node 3 in this case) twice. This should normally not happen with a name generator question; it could (in real data) be a mistake by the respondent or a mistake in data entry. It is however something to fix, in most cases. To do so, we select only the rows of the edge list that are unique on “from” and “to”. edge_list_3a &lt;- edge_list_3a %&gt;% distinct(from, to, .keep_all = TRUE) Note: we somewhat arbitrarily keep only the first occurrence of the duplicate friend. If the information in sourcevar is meaningful, this choice may matter. Now that the problem is fixed, we can properly import the data into a network object. g3a_nw &lt;- as.network(edge_list_3a, matrix.type = &quot;edgelist&quot;, vertices = nodelist_3a) plot(g3a_nw) 6.3 Multiple networks Now let’s try to import the two classes into a network object at once, as if they are a single network. edge_list &lt;- df %&gt;% select(namenr, friend1:friend2) %&gt;% melt(id.vars = &quot;namenr&quot;) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns all_vertices &lt;- append(edge_list$from, edge_list$to) %&gt;% unique() %&gt;% as.data.frame() %&gt;% rename(namenr = &quot;.&quot;) nodelist &lt;- df %&gt;% select(namenr,age, schoolnr) %&gt;% merge(all_vertices, by = &quot;namenr&quot;, all.y = T, all.x = T) g2 &lt;- graph_from_data_frame(edge_list, vertices = nodelist) ## Error in graph_from_data_frame(edge_list, vertices = nodelist): Duplicate vertex names Houston, we’ve got a problem. We need to be able to differentiate between the nodes from different classes, both for repondents (“egos”) and nominees (“alters”). Let’s start with the ego, which is the simplest case. We can create a unique student ID by combining the class identifier and the within-class identifier: df &lt;- df %&gt;% mutate(id_pupil = paste0(schoolnr,namenr)) Now let’s start over, using this new identifier instead of ‘namenr’. edge_list &lt;- df %&gt;% select(id_pupil, schoolnr, friend1:friend2) %&gt;% melt(id.vars = c(&quot;id_pupil&quot;,&quot;schoolnr&quot;)) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;id_pupil&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns edge_list ## from to schoolnr sourcevar ## 1 1a1 2 1a friend1 ## 2 1a2 3 1a friend1 ## 3 1a3 1 1a friend1 ## 4 2b1 2 2b friend1 ## 5 2b2 1 2b friend1 ## 6 2b4 2 2b friend1 ## 7 2b5 6 2b friend1 ## 8 1a1 4 1a friend2 ## 9 2b1 3 2b friend2 ## 10 2b2 3 2b friend2 ## 11 2b3 4 2b friend2 ## 12 2b4 5 2b friend2 Now we can also create the unique student ID for alters in the ‘to’ column of the edge list: edge_list &lt;- edge_list %&gt;% mutate(to = paste0(schoolnr,to)) edge_list ## from to schoolnr sourcevar ## 1 1a1 1a2 1a friend1 ## 2 1a2 1a3 1a friend1 ## 3 1a3 1a1 1a friend1 ## 4 2b1 2b2 2b friend1 ## 5 2b2 2b1 2b friend1 ## 6 2b4 2b2 2b friend1 ## 7 2b5 2b6 2b friend1 ## 8 1a1 1a4 1a friend2 ## 9 2b1 2b3 2b friend2 ## 10 2b2 2b3 2b friend2 ## 11 2b3 2b4 2b friend2 ## 12 2b4 2b5 2b friend2 The result is a neat list of within-class ties. We continue with creating the node list: all_vertices &lt;- append(edge_list$from, edge_list$to) %&gt;% unique() %&gt;% as.data.frame() %&gt;% rename(id_pupil = &quot;.&quot;) nodelist &lt;- df %&gt;% select(id_pupil,age, schoolnr) %&gt;% merge(all_vertices, by = &quot;id_pupil&quot;, all.y = T, all.x = T) g2 &lt;- graph_from_data_frame(edge_list, vertices = nodelist) plot(g2, vertex.color = ifelse(V(g2)$schoolnr==&quot;1a&quot;, &quot;lightblue&quot;, &quot;red&quot;)) Almost correct! The one thing to fix is that now we don’t have the schoolnr for node 2b6. The approach that we used earlier doesn’t work now (why not?), but recall that we already have schoolnr for each edge in ‘edge_list’. We use that to keep schoolnr with the list of all vertices (all_vertices) and keep it in the merge with the node list. The method for constructing all_vertices is a little different now. all_vertices &lt;- edge_list %&gt;% select(id_pupil = from, schoolnr) %&gt;% bind_rows(edge_list %&gt;% select(id_pupil = to, schoolnr)) %&gt;% unique() %&gt;% rename(schoolnr_from_edges = schoolnr) nodelist &lt;- df %&gt;% select(id_pupil,age, schoolnr) %&gt;% merge(all_vertices, by = &quot;id_pupil&quot;, all.y = T, all.x = T) We now replace any NA’s in schoolnr with the value in schoolnr_from_edges. For tidiness, we remove schoolnr_from_edges as we don’t need it to be imported in our network object (of course there may be scenarios where you may want to keep it). nodelist &lt;- nodelist %&gt;% mutate(schoolnr = coalesce(schoolnr,schoolnr_from_edges)) %&gt;% select(-schoolnr_from_edges) g2 &lt;- graph_from_data_frame(edge_list, vertices = nodelist) plot(g2, vertex.color = ifelse(V(g2)$schoolnr==&quot;1a&quot;, &quot;lightblue&quot;, &quot;red&quot;)) Done! 6.4 Dyads-as-cases For some analyses, it can be useful to have a dataset in which the rows represent all all dyads (i.e., all pairs of nodes) in the network, with a variable (0/1) indicating whether they are connected. Conceptually, this is similar to an adjacency matrix in which each cell represents a connection between two nodes, but here, we have a row for each cell. As always, we start with loading the relevant packages. library(igraph) library(tidyverse) library(reshape2) As an example, we use a small toy data set, which contains (fictional) “name generator” data for two groups of individuals. url1 &lt;- &quot;https://github.com/rensec/sasr08/raw/main/toy_name_generator_data.csv&quot; df &lt;- read.csv(file = url1) table(df$schoolnr) ## ## 1a 2b ## 5 5 We extract the data for one of the groups, and create a graph from it: cls &lt;- &quot;1a&quot; edge_list &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr, friend1:friend2) %&gt;% melt(id.vars = &quot;namenr&quot;) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns nodelist &lt;- df %&gt;% filter(schoolnr == cls) %&gt;% select(namenr,age) g1a &lt;- graph_from_data_frame(edge_list, vertices = nodelist) plot(g1a) 6.4.1 Create a dyads-as-cases dataset From the igraph object, we can create a dyads-as-cases dataset. We start by extracting the edges from the graph, and adding a variable indicating that they are connected. Then, we create a list of all possible combinations of nodes, and match this to the list of edges. If there is no connection, we set the variable to 0. Note the use of the igraph:: namespace to avoid a conflict with the dplyr function by the same name. Note furthermore that we first created an igraph object from the edge list, and now extract the edge list from the igraph object. We could have skipped both steps altogether and work directly from the edge list, but the igraph object is still nice to have to plot the network. Without these steps, we would not need igraph at all. dyads &lt;- igraph::as_data_frame(g1a, what = &quot;edges&quot;) # start with extracting all edges from the graph object dyads$connected &lt;- 1 # add a variable indicating that they are connected dyads &lt;- dyads %&gt;% full_join(expand.grid(from = V(g1a)$name, to = V(g1a)$name), by = c(&quot;from&quot;, &quot;to&quot;)) %&gt;% # create a list of all combinations of nodes, and match this to whether they are connected mutate(connected = ifelse(is.na(connected), 0, connected)) %&gt;% # if there is no connection, set connected to 0 filter(from != to) %&gt;% # remove the diagonal select(from, to, connected) # keep only from, to and connected We now have a data frame with 20 rows. Verify for yourself that this is indeed the number of rows we should expect. Note that while the “connected” variable is now a binary variable, conceptually, this could also take other values, for example values that represent the strength of the connection, or negative values. Next, we can merge this data set with the original data, to add information about the nodes. Because the node names are extracted from the igraph object as characters, we need to convert them to numeric values first. dyads &lt;- dyads %&gt;% mutate(from = as.numeric(from), to = as.numeric(to)) %&gt;% # convert the node names to numeric) left_join(nodelist %&gt;% select(namenr, age), by = c(&quot;from&quot; = &quot;namenr&quot;)) %&gt;% filter(from != to) %&gt;% # remove the diagonal rename(age_from = age) %&gt;% left_join(nodelist %&gt;% select(namenr, age), by = c(&quot;to&quot; = &quot;namenr&quot;)) %&gt;% rename(age_to = age) With this information added, we can can also calculate further characteristics of the dyads, such as the age difference between the nodes. ASSIGNMENT: Add a variable that contains the absolute age difference between the two nodes in the dyad. 6.4.2 Extend to multiple networks The code above can be extended to multiple networks. We can use a function to create the dyads-as-cases dataset for each subset in df, and then apply this function to each network. create_dyads &lt;- function(subnet){ # Create the edgelist dyads &lt;- subnet %&gt;% select(namenr, friend1:friend2) %&gt;% melt(id.vars = &quot;namenr&quot;) %&gt;% #make long filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;variable&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns dyads$connected &lt;- 1 # add a variable indicating that they are connected # Create a list of all possible dyads dyads &lt;- dyads %&gt;% full_join(expand.grid(from = subnet$namenr, to = subnet$namenr), by = c(&quot;from&quot;, &quot;to&quot;)) %&gt;% # create a list of all combinations of nodes, and match this to whether they are connected mutate(connected = ifelse(is.na(connected), 0, connected)) %&gt;% # if there is no connection, set connected to 0 filter(from != to) %&gt;% # remove the diagonal select(from, to, connected) # keep only from, to and connected # Add the group identifier dyads$schoolnr &lt;- unique(subnet$schoolnr) dyads &lt;- select(dyads, schoolnr, from, to, connected) # and move it to the front for convenience return(dyads) } We can now apply this function to each subset of the data frame, and then bind the results together. dyads &lt;- df %&gt;% group_split(schoolnr) %&gt;% # Split the dataframe into a list of dataframes, one for each value of schoolnr map(create_dyads) %&gt;% # apply the function to each subset list_rbind() # bind the results together From here, we can add the node information as before, matching on “from” or “to” and “schoolnr”. ASSIGNMENT: Add a variable the variables “age_from”, “age_to”, and “age_diff” once more. QUESTION: We now create an edge list for each subgroup (class) in the data set, process that, and add the results together. We could also try to take the entire data set at once, follow the same procedure, and create one large dyads-as-cases data set. What would go wrong if we did that (hint: there are multiple things)? "],["solutions-to-tutorial-3.html", "7 Solutions to Tutorial 3 7.1 Preliminaries 7.2 Importing the data 7.3 Is the network directed? 7.4 A first visualization 7.5 A ‘five(ish) number summary’ 7.6 Comparing degree centrality", " 7 Solutions to Tutorial 3 7.1 Preliminaries library(igraph) library(haven) # to read Stata files library(reshape2) library(tidyverse) PupilsWaveV &lt;- read_dta(file = &quot;PupilsWaveV.dta&quot;) class12b &lt;- PupilsWaveV %&gt;% filter(schoolnr == &quot;12b&quot;) # keep only one class 7.2 Importing the data elist &lt;- class12b %&gt;% select(namenr, friend1:friend12) %&gt;% # select only the &quot; best friends&quot; network pivot_longer(c(friend1:friend12)) %&gt;% filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;name&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns nodelist &lt;- class12b %&gt;% select(namenr,sex, age) %&gt;% rename(name = &quot;namenr&quot;) classnet &lt;- graph_from_data_frame(elist, vertices = nodelist) 7.3 Is the network directed? is_directed(classnet) ## [1] TRUE Yes it is (as expected)! 7.4 A first visualization plot(classnet) EXTRA: This doesn’t look very nice. Somehow the layout that plot() uses here doesn’t seem to work out very well in this case (even thought the default algorithm tries to optimize the layout for the graph), so perhaps we can try another one, such as the Kamada-Kawai algorithm which often works well for smaller graphs (see here for more details on layout options for plot()). Also, the arrowheads seem a bit large, so let’s give them a smaller size. layout &lt;- layout_with_kk(classnet) plot(classnet, layout = layout, edge.arrow.size = .5) That’s already better! 7.5 A ‘five(ish) number summary’ 7.5.1 Size ecount(classnet) ## [1] 91 vcount(classnet) ## [1] 26 7.5.2 Density edge_density(classnet) ## [1] 0.14 7.5.3 Components count_components(classnet) ## [1] 1 7.5.4 Diameter and average distance diameter(classnet) ## [1] 7 mean_distance(classnet) ## [1] 2.853598 7.5.5 Clustering coefficient transitivity(classnet, type=&quot;average&quot;) ## [1] 0.5886984 7.6 Comparing degree centrality V(classnet)$degree &lt;- igraph::degree(classnet) Note:: the namespace igraph:: is not necessary if you only have igraph loaded, but in the creation of the online version of this file, it was necessary to avoid confusion with the network package. d &lt;- igraph::as_data_frame(classnet, what = &quot;vertices&quot;) t.test(degree ~ sex, alternative = &quot;less&quot;, conf.level = .95, var.equal = TRUE, data = d) ## ## Two Sample t-test ## ## data: degree by sex ## t = 0.59944, df = 24, p-value = 0.7228 ## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0 ## 95 percent confidence interval: ## -Inf 3.274745 ## sample estimates: ## mean in group 1 mean in group 2 ## 7.294118 6.444444 Indeed, girls have higher degree, but the difference is not significant. How do we know that ‘2’ means ‘male’? Check out the code book (on Blackboard)! Alternatively, you can also use print_labels() from the haven package to show the labels of the original Stata dataset. 7.6.1 Visualization with degree and gender plot(classnet, vertex.size = V(classnet)$degree +5, # Adding 5 to make all nodes somewhat larger vertex.color= V(classnet)$sex, edge.arrow.size = .5, layout=layout_with_kk(classnet), margin = -.1 ) Note: For vertex colors, we here simply let the colors be determined by the values that go with ‘female’ (1) and ‘male’ (2). A more elegant way is the following (in which we also drop the vertex labels): plot(classnet, vertex.size = V(classnet)$degree + 5, vertex.color= ifelse(V(classnet)$sex == 2, &quot;royalblue&quot;, &quot;red3&quot;), edge.arrow.size = .5, layout=layout_with_kk(classnet), vertex.label = NA, margin = -.1 ) "],["solutions-to-tutorial-4---spatial-models-in-r.html", "8 Solutions to Tutorial 4 - Spatial Models in R 8.1 Preliminaries 8.2 Open the dataset 8.3 Linear regression 8.4 Multilevel model 8.5 Adjacency matrix 8.6 Transform to a weights list object 8.7 Moran’s I test and LM tests 8.8 Spatial lag model 8.9 SEM and SAC 8.10 SDM, SDEM, and GNM 8.11 Conclusion", " 8 Solutions to Tutorial 4 - Spatial Models in R 8.1 Preliminaries Load different packages: library(haven) library(tidyverse) library(igraph) library(lme4) ## Registered S3 methods overwritten by &#39;lme4&#39;: ## method from ## simulate.formula ergm ## simulate.formula_lhs ergm library(spdep) library(spatialreg) 8.2 Open the dataset Get Knecht data: PupilsWaveV &lt;- read_dta(file = &quot;PupilsWaveV.dta&quot;) 8.3 Linear regression Clean variables: PupilsWaveV$acthomew &lt;- 5-PupilsWaveV$acthomew PupilsWaveV$sex &lt;- PupilsWaveV$sex-1 PupilsWaveV$sex &lt;- 1-PupilsWaveV$sex PupilsWaveV$acthomew[PupilsWaveV$acthomew == 9] &lt;- NA Linear regression: olsreg &lt;- lm(acthomew ~ sex + age, data=PupilsWaveV) summary(olsreg) ## ## Call: ## lm(formula = acthomew ~ sex + age, data = PupilsWaveV) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.1157 -0.1590 -0.1157 0.8410 0.8996 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.93214 0.35102 8.353 &lt;2e-16 *** ## sex 0.04332 0.02847 1.522 0.128 ## age 0.01530 0.02885 0.530 0.596 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7698 on 2943 degrees of freedom ## (50 observations deleted due to missingness) ## Multiple R-squared: 0.0008427, Adjusted R-squared: 0.0001637 ## F-statistic: 1.241 on 2 and 2943 DF, p-value: 0.2892 We see that girls do more homework than boys, but this is not statistically significant. 8.4 Multilevel model ml &lt;- lmer(acthomew ~ sex + age + (1 | schoolnr), PupilsWaveV) summary(ml) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: acthomew ~ sex + age + (1 | schoolnr) ## Data: PupilsWaveV ## ## REML criterion at convergence: 6818.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -9.0462 -0.2954 -0.1380 1.0497 1.4727 ## ## Random effects: ## Groups Name Variance Std.Dev. ## schoolnr (Intercept) 0.01431 0.1196 ## Residual 0.57841 0.7605 ## Number of obs: 2946, groups: schoolnr, 125 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 2.98206 0.35597 8.377 ## sex 0.04452 0.02837 1.569 ## age 0.01119 0.02923 0.383 ## ## Correlation of Fixed Effects: ## (Intr) sex ## sex -0.121 ## age -0.998 0.082 We again see that girls do more homework than boys, but this is not statistically significant. 8.5 Adjacency matrix Keep only the class 12b: class12b &lt;- PupilsWaveV %&gt;% filter(schoolnr == &quot;12b&quot;) # keep only one class Fetch the spatial weight matrix: friendsadjlist &lt;- class12b %&gt;% select(namenr, friend1:friend12) class(friendsadjlist) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; It is currently in the adjacency list format. We first transform these data into edge list format: friendsedgelist &lt;- class12b %&gt;% select(namenr, friend1:friend12) %&gt;% # select only the &quot; best friends&quot; network pivot_longer(c(friend1:friend12)) %&gt;% filter(!is.na(value)) %&gt;% # drop the missings rename(from =&quot;namenr&quot;, to = &quot;value&quot;, sourcevar= &quot;name&quot;) %&gt;% #just nice for interpretation relocate(to, .after=from) #move around the columns We lost the potential isolates (observation 15). We also would like information on the nodes: friendsnodelist &lt;- class12b %&gt;% select(namenr,sex,age,acthomew) %&gt;% rename(name = &quot;namenr&quot;) Transform to igraph object: friendsgraph &lt;- graph_from_data_frame(friendsedgelist, vertices = friendsnodelist) class(friendsgraph) ## [1] &quot;igraph&quot; Plot the friends network: plot(friendsgraph) layout &lt;- layout_with_kk(friendsgraph) plot(friendsgraph, layout = layout, edge.arrow.size = .5) Transform to adjacency matrix: friendsadjmatrix &lt;- as_adjacency_matrix(friendsgraph, sparse = FALSE) class(friendsadjmatrix) ## [1] &quot;matrix&quot; &quot;array&quot; 8.6 Transform to a weights list object friends &lt;- mat2listw(friendsadjmatrix, row.names = NULL, zero.policy =TRUE, style=&quot;W&quot;) class(friends) ## [1] &quot;listw&quot; &quot;nb&quot; Style W means row-standardized. 8.7 Moran’s I test and LM tests Moran’s I test: moran.test(class12b$acthomew, friends, zero.policy = TRUE) ## ## Moran I test under randomisation ## ## data: class12b$acthomew ## weights: friends ## n reduced by no-neighbour observations ## ## Moran I statistic standard deviate = -1.2823, p-value = 0.9001 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## -0.24084048 -0.04166667 0.02412595 We set zero.policy to TRUE because we have isolates. Moran’s I test does not reject the null hypothesis, suggesting a lack of dependence in the data. However, we only have 26 observations, making it very difficult to reject any null hypothesis. Thus, we will ignore this. Lagrange multiplier tests for spatial lag and spatial error dependencies: olsregnew &lt;- lm(acthomew ~ sex + age, data=friendsnodelist) summary(olsregnew) ## ## Call: ## lm(formula = acthomew ~ sex + age, data = friendsnodelist) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.22870 -0.22870 -0.09865 0.77130 0.90135 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.7534 3.9043 0.449 0.658 ## sex 0.1300 0.3206 0.406 0.689 ## age 0.1121 0.3217 0.349 0.731 ## ## Residual standard error: 0.7767 on 23 degrees of freedom ## Multiple R-squared: 0.01168, Adjusted R-squared: -0.07426 ## F-statistic: 0.136 on 2 and 23 DF, p-value: 0.8736 lm.RStests(olsregnew, friends, test=c(&quot;LMlag&quot;, &quot;LMerr&quot;), zero.policy = TRUE) ## ## Rao&#39;s score (a.k.a Lagrange multiplier) diagnostics for spatial ## dependence ## ## data: ## model: lm(formula = acthomew ~ sex + age, data = friendsnodelist) ## test weights: friends ## ## RSlag = 4.1954, df = 1, p-value = 0.04053 ## ## ## Rao&#39;s score (a.k.a Lagrange multiplier) diagnostics for spatial ## dependence ## ## data: ## model: lm(formula = acthomew ~ sex + age, data = friendsnodelist) ## test weights: friends ## ## RSerr = 2.1604, df = 1, p-value = 0.1416 We reject the null hypothesis for the LMlag, but not for the LMerr. Hence, we should use the spatial lag model. But we will use both in this exercise. 8.8 Spatial lag model slm &lt;- lagsarlm(acthomew ~ sex + age, data = friendsnodelist, friends, zero.policy = TRUE, Durbin=FALSE) summary(slm) ## ## Call:lagsarlm(formula = acthomew ~ sex + age, data = friendsnodelist, ## listw = friends, Durbin = FALSE, zero.policy = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.163673 -0.319492 -0.032362 0.448553 1.009788 ## ## Type: lag ## Regions with no neighbours included: ## 15 ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.102918 3.183678 0.0323 0.9742 ## sex 0.040761 0.259872 0.1569 0.8754 ## age 0.377584 0.271005 1.3933 0.1635 ## ## Rho: -0.49008, LR test value: 6.3751, p-value: 0.011573 ## Asymptotic standard error: 0.15619 ## z-value: -3.1378, p-value: 0.0017022 ## Wald statistic: 9.8458, p-value: 0.0017022 ## ## Log likelihood: -25.54022 for lag model ## ML residual variance (sigma squared): 0.39343, (sigma: 0.62724) ## Number of observations: 26 ## Number of parameters estimated: 5 ## AIC: 61.08, (AIC for lm: 65.456) ## LM test for residual autocorrelation ## test value: 0.61521, p-value: 0.43283 We only interpret the coefficients because of the low sample size, we will ignore the significance. Females tend to do more homework than males. The older you are the more homework you do. Negative rho: if your friends do homework, you are less likely to do it! Impacts: set.seed(123456) im&lt;-impacts(slm, listw=friends, zstats=TRUE, R=200) sums&lt;-summary(im, zstats=T) data.frame(sums$res) ## direct indirect total ## 1 0.04325743 -0.01590232 0.02735511 ## 2 0.40070523 -0.14730748 0.25339775 data.frame(sums$pzmat) ## Direct Indirect Total ## sex 0.9538984 0.9973611 0.9330865 ## age 0.1586682 0.1982805 0.1618443 Direct effects tend to be larger than indirect ones and of the reversed sign. Direct effect: if you are a girl, you tend to do more homework than if you are a boy. This impact includes the effect of feedback loops where you affect your friend and your friend influences you. So if you are a girl, this will affect your homework, then will pass through the homework of friends, and then back to your homework. Indirect effect: if your friend is a girl, you will also tend to do less homework, taking into account the feedback loop where your friend influences their friends etc. Rho is negative: if your friends do more homework, you will do less homework. The difference between the impacts and the point estimates that we had before calculating impacts is that point estimates do not take feedback loops into account. Thus, interpret the impacts when having an autoregressive term. 8.9 SEM and SAC Spatial error model: sem &lt;- errorsarlm(acthomew ~ sex + age, data = friendsnodelist, friends, zero.policy = TRUE, Durbin=FALSE) summary(sem) ## ## Call:errorsarlm(formula = acthomew ~ sex + age, data = friendsnodelist, ## listw = friends, Durbin = FALSE, zero.policy = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.219368 -0.362548 -0.058648 0.668676 0.912751 ## ## Type: error ## Regions with no neighbours included: ## 15 ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 2.562833 3.153258 0.8128 0.4164 ## sex 0.063223 0.173322 0.3648 0.7153 ## age 0.047439 0.258850 0.1833 0.8546 ## ## Lambda: -0.6606, LR test value: 4.4195, p-value: 0.03553 ## Asymptotic standard error: 0.20347 ## z-value: -3.2466, p-value: 0.0011678 ## Wald statistic: 10.541, p-value: 0.0011678 ## ## Log likelihood: -26.51801 for error model ## ML residual variance (sigma squared): 0.40272, (sigma: 0.6346) ## Number of observations: 26 ## Number of parameters estimated: 5 ## AIC: 63.036, (AIC for lm: 65.456) #Here impacts are the same as point estimates as there are no autoregressive terms. #The lambda is negative: it means that unobserved factors of the friends are reducing your homework. Spatial autoregressive combined model: sac &lt;- sacsarlm(acthomew ~ sex + age, data = friendsnodelist, friends, zero.policy = TRUE, Durbin=FALSE) summary(sac) ## ## Call:sacsarlm(formula = acthomew ~ sex + age, data = friendsnodelist, ## listw = friends, Durbin = FALSE, zero.policy = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.213266 -0.403948 -0.021075 0.511254 0.959576 ## ## Type: sac ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.483330 3.228153 0.1497 0.8810 ## sex 0.051863 0.193124 0.2685 0.7883 ## age 0.317521 0.286559 1.1080 0.2678 ## ## Rho: -0.38048 ## Asymptotic standard error: 0.21818 ## z-value: -1.7439, p-value: 0.081178 ## Lambda: -0.40183 ## Asymptotic standard error: 0.32254 ## z-value: -1.2458, p-value: 0.21283 ## ## LR test value: 7.3747, p-value: 0.025038 ## ## Log likelihood: -25.0404 for sac model ## ML residual variance (sigma squared): 0.37267, (sigma: 0.61047) ## Number of observations: 26 ## Number of parameters estimated: 6 ## AIC: 62.081, (AIC for lm: 65.456) Also calculate impacts given that there is an autoregressive term. Same interpretation as above. 8.10 SDM, SDEM, and GNM Spatial Durbin model: sdm &lt;- lagsarlm(acthomew ~ sex + age, data = friendsnodelist, friends, zero.policy = TRUE, Durbin=TRUE) summary(sdm) ## ## Call:lagsarlm(formula = acthomew ~ sex + age, data = friendsnodelist, ## listw = friends, Durbin = TRUE, zero.policy = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.147316 -0.398493 -0.051684 0.554396 0.988842 ## ## Type: mixed ## Regions with no neighbours included: ## 15 ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.278539 3.169616 0.0879 0.9300 ## sex -0.137293 0.533851 -0.2572 0.7970 ## age 0.353229 0.293066 1.2053 0.2281 ## lag.sex 0.256152 0.609621 0.4202 0.6744 ## lag.age 0.056033 0.096544 0.5804 0.5617 ## ## Rho: -0.68079, LR test value: 4.6068, p-value: 0.031846 ## Asymptotic standard error: 0.19698 ## z-value: -3.4562, p-value: 0.00054779 ## Wald statistic: 11.946, p-value: 0.00054779 ## ## Log likelihood: -25.1013 for mixed model ## ML residual variance (sigma squared): 0.35844, (sigma: 0.5987) ## Number of observations: 26 ## Number of parameters estimated: 7 ## AIC: 64.203, (AIC for lm: 66.809) ## LM test for residual autocorrelation ## test value: 1.652, p-value: 0.19869 Also calculate impacts given that there is an autoregressive term. Same interpretation as above. Note that the lag terms are the point estimates of the friends, but without taking into account the feedback loops. Spatial Durbin error model: sdem &lt;- errorsarlm(acthomew ~ sex + age, data = friendsnodelist, friends, zero.policy = TRUE, Durbin=TRUE) summary(sdem) ## ## Call:errorsarlm(formula = acthomew ~ sex + age, data = friendsnodelist, ## listw = friends, Durbin = TRUE, zero.policy = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.026601 -0.370501 -0.026601 0.463311 0.941782 ## ## Type: error ## Regions with no neighbours included: ## 15 ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.96268 3.07793 0.3128 0.75446 ## sex -0.66948 0.52570 -1.2735 0.20284 ## age 0.31653 0.28479 1.1115 0.26636 ## lag.sex 0.83964 0.59342 1.4149 0.15709 ## lag.age -0.14550 0.07921 -1.8369 0.06622 ## ## Lambda: -0.77077, LR test value: 4.7916, p-value: 0.028599 ## Asymptotic standard error: 0.17951 ## z-value: -4.2937, p-value: 1.7569e-05 ## Wald statistic: 18.436, p-value: 1.7569e-05 ## ## Log likelihood: -25.00887 for error model ## ML residual variance (sigma squared): 0.34276, (sigma: 0.58546) ## Number of observations: 26 ## Number of parameters estimated: 7 ## AIC: 64.018, (AIC for lm: 66.809) No need to calculate impacts here as there are no autoregressive terms. General nested model: gnm &lt;- sacsarlm(acthomew ~ sex + age, data = friendsnodelist, friends, zero.policy = TRUE, Durbin=TRUE) summary(gnm) ## ## Call:sacsarlm(formula = acthomew ~ sex + age, data = friendsnodelist, ## listw = friends, Durbin = TRUE, zero.policy = TRUE) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.113476 -0.304694 -0.052416 0.508381 0.988249 ## ## Type: sacmixed ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.390782 3.138685 0.1245 0.9009 ## sex -0.528158 0.532858 -0.9912 0.3216 ## age 0.363804 0.290619 1.2518 0.2106 ## lag.sex 0.694981 0.598435 1.1613 0.2455 ## lag.age -0.035517 0.321437 -0.1105 0.9120 ## ## Rho: -0.41913 ## Asymptotic standard error: 1.2085 ## z-value: -0.34682, p-value: 0.72873 ## Lambda: -0.55821 ## Asymptotic standard error: 1.1401 ## z-value: -0.4896, p-value: 0.62442 ## ## LR test value: 8.5977, p-value: 0.07198 ## ## Log likelihood: -24.42892 for sacmixed model ## ML residual variance (sigma squared): 0.33957, (sigma: 0.58273) ## Number of observations: 26 ## Number of parameters estimated: 8 ## AIC: 64.858, (AIC for lm: 65.456) Also calculate impacts here. Same interpretation as in the other models. 8.11 Conclusion Think about it! "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
